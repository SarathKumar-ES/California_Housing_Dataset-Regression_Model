{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "da8bd327-425f-4f4f-a617-a87808179965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "\n",
    "import pandas as pd  # For Data Handling\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt  # For Visualization\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler  # For Preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression  # Regression Models\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aab7509-d14f-471e-8a0b-034e10e1c977",
   "metadata": {},
   "source": [
    "# 1. Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1ea9651a-0733-47e6-ab84-3f735ce29e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the Dataset\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "data = fetch_california_housing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1f276f8d-666d-42d1-ac59-d95f5d3dd834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>MedHouseValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "      <td>4.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "      <td>3.585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "      <td>3.521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "      <td>3.422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  MedHouseValue  \n",
       "0    -122.23          4.526  \n",
       "1    -122.22          3.585  \n",
       "2    -122.24          3.521  \n",
       "3    -122.25          3.413  \n",
       "4    -122.25          3.422  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to pandas DataFrame\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['MedHouseValue'] = data.target # Adding the target column\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e43ba1a-bd25-4058-a515-6ce49b0092e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MedInc           0\n",
       "HouseAge         0\n",
       "AveRooms         0\n",
       "AveBedrms        0\n",
       "Population       0\n",
       "AveOccup         0\n",
       "Latitude         0\n",
       "Longitude        0\n",
       "MedHouseValue    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Missing values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6a3907b5-97fa-4ee9-a664-8b536df8e450",
   "metadata": {},
   "source": [
    "There is no missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "185e936f-0389-4311-8d9e-54d9d1715418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Duplicate Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking Duplicate rows\n",
    "duplicates = df.duplicated().sum()\n",
    "print(f\"Total Duplicate Rows: {duplicates}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "96afdfbe-6997-459d-b507-749506dd1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling Using Standard Scaler\n",
    "# To separate feature and target\n",
    "x = df.drop('MedHouseValue', axis=1)\n",
    "y = df['MedHouseValue']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(X)\n",
    "# StandardScaler transforms data to have mean = 0 and standard deviation = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131d0255-6d27-44ac-ba80-120e58ad5b4e",
   "metadata": {},
   "source": [
    "# 2. Regression Algorithm Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8d6c0cfd-4e56-45fb-b357-e3e159f5a2c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression Result:\n",
      "Mean Squared Error: 0.56\n",
      "Mean Absolut Error: 0.53\n",
      "R-Squared: 0.58\n"
     ]
    }
   ],
   "source": [
    "# Using Liner regression\n",
    "\n",
    "# To split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(x_train, y_train)\n",
    "\n",
    "# For prediction and evaluation\n",
    "y_pred = lr.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Linear Regression Result:\")\n",
    "print(f\"Mean Squared Error: {mse:.2f}\")\n",
    "print(f\"Mean Absolut Error: {mae:.2f}\")\n",
    "print(f\"R-Squared: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12510168-1acb-44f8-98aa-19ba53c04dfd",
   "metadata": {},
   "source": [
    "# What is Linear Regression? \n",
    "Linear Regression is one of the simplest and most commonly used algorithms in regression tasks. It models the relationship between one or more independent variables (features) and a dependent variable (target) by fitting a straight line (or hyperplane in multiple dimensions) to the data. The model learns the best values for these coefficients by minimizing the mean squared error between the predicted values and target values.\n",
    "\n",
    "# Why is it used in the regression?\n",
    "- The California Housing dataset is a regression problem, where the target is a continuous value (median house price), making Linear Regression a valid choice.\n",
    "- It works well as a baseline model, helping to set a reference point for comparing more complex models.\n",
    "- It is easy to interpret, and we can understand the impact of each feature on the price.\n",
    "- The dataset features (like average income, number of rooms, etc.) often have linear relationships with housing prices, making Linear Regression potentially effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0e18e1b0-85a9-4d64-bf47-6ae91a358332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Decision Tree Regressor\n",
    "# Initialize the model\n",
    "dt_model = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# To train the model\n",
    "dt_model.fit(x_train, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred_dt = dt_model.predict(x_test)\n",
    "\n",
    "# To Evaluate the model\n",
    "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
    "mae_dt = mean_absolute_error(y_test, y_pred_dt)\n",
    "r2_dt = r2_score(y_test, y_pred_dt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "016734e2-53c3-4389-a666-e0a166b6ecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Regressor Results:\n",
      "Mean Squared Error: 0.49\n",
      "Mean Absolute Error: 0.45\n",
      "R-squared Score: 0.62\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Decision Tree Regressor Results:\")\n",
    "print(f\"Mean Squared Error: {mse_dt:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_dt:.2f}\")\n",
    "print(f\"R-squared Score: {r2_dt:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a3c20-dbfe-4039-975b-a1a023cd4898",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor:\n",
    "A Decision Tree Regressor splits the data into smaller and smaller subsets by asking yes/no questions based on feature values. It keeps doing this until it reaches a leaf node, where it assigns a prediction (average of target values in that node). It works non-linearly, unlike linear regression, so it's great at capturing complex patterns.\n",
    "\n",
    "# Why It's Suitable?\n",
    "-It does not require feature scaling, which simplifies preprocessing.\n",
    "-It can automatically handle feature interactions and identify important features.\n",
    "-Easy to visualize and interpret for small trees.\n",
    "-Housing prices can depend on complex combinations of features. Decision Trees capture non-linear relationships well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "41120a4c-4fb2-42a3-a774-44eafe9dc9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Random Forest Regressor\n",
    "\n",
    "# Defining the model\n",
    "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# To train the model\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = rf_model.predict(x_test)\n",
    "\n",
    "# To evaluate the model\n",
    "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
    "mae_rf = mean_absolute_error(y_test, y_pred_rf)\n",
    "r2_rf = r2_score(y_test, y_pred_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "80f5702c-2a8a-41cd-a42a-e62933f81095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor Results:\n",
      "Mean Squared Error: 0.26\n",
      "Mean Absolute Error: 0.33\n",
      "R-squared Score: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Random Forest Regressor Results:\")\n",
    "print(f\"Mean Squared Error: {mse_rf:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_rf:.2f}\")\n",
    "print(f\"R-squared Score: {r2_rf:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e78281eb-c49f-4017-b9ab-368fd648b2b8",
   "metadata": {},
   "source": [
    "#  How Random Forest Regressor Works\n",
    "A Random Forest Regressor is an ensemble model that builds many decision trees and averages their predictions. It creates multiple decision trees using random subsets of the data (both rows and columns). Each tree learns differently because of the randomness. For regression, it averages the predictions of all the trees to give the final result. This reduces the chance of overfitting that a single Decision Tree might face.\n",
    "\n",
    "# Why It’s Suitable? \n",
    "-The dataset has complex, non-linear relationships — Random Forest can handle that easily.\n",
    "-It’s robust against noise and overfitting due to averaging.\n",
    "-It can handle a mix of features and capture important interactions.\n",
    "-No need for scaling — it's scale-invariant.\n",
    "-Very accurate and stable compared to individual models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "617012fb-ee1e-4ada-917c-a029f60efe1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Gradient Boosting Regressor\n",
    "\n",
    "# Initialize the model\n",
    "gb_model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "gb_model.fit(x_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_gb = gb_model.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "mae_gb = mean_absolute_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c5bce2de-99dd-4398-ac9b-5d100d429b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Regressor Results:\n",
      "Mean Squared Error: 0.29\n",
      "Mean Absolute Error: 0.37\n",
      "R-squared Score: 0.78\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Gradient Boosting Regressor Results:\")\n",
    "print(f\"Mean Squared Error: {mse_gb:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_gb:.2f}\")\n",
    "print(f\"R-squared Score: {r2_gb:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "347e3423-d386-4c43-9c7c-2daa24398b5a",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor\n",
    "It starts with a simple model (usually a Decision Tree). Then it calculates the error (called residuals). It builds a new tree to predict the residuals (the mistakes). Repeats this process multiple times, and the final prediction is the sum of all previous corrections. This step-by-step correction is called boosting.\n",
    "\n",
    "# Why It’s Suitable \n",
    "- It captures complex, non-linear relationships very well.\n",
    "- Usually gives high accuracy for structured/tabular data like this one.\n",
    "- Can handle outliers better than some other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d0f746aa-7f28-46fc-a7aa-7428ea7a1a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Support Vector Regressor (SVR)\n",
    "\n",
    "# To define the model\n",
    "svr_model = SVR(kernel='rbf')  # 'rbf' is the default kernel and good for non-linear data\n",
    "\n",
    "# To train the model\n",
    "svr_model.fit(x_train, y_train)\n",
    "\n",
    "# Predicting on test data\n",
    "y_pred_svr = svr_model.predict(x_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse_svr = mean_squared_error(y_test, y_pred_svr)\n",
    "mae_svr = mean_absolute_error(y_test, y_pred_svr)\n",
    "r2_svr = r2_score(y_test, y_pred_svr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ef6d95f2-a3e8-4660-aa68-69eb0c97378d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Support Vector Regressor (SVR) Results:\n",
      "Mean Squared Error: 0.36\n",
      "Mean Absolute Error: 0.40\n",
      "R-squared Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Print the results\n",
    "print(\"Support Vector Regressor (SVR) Results:\")\n",
    "print(f\"Mean Squared Error: {mse_svr:.2f}\")\n",
    "print(f\"Mean Absolute Error: {mae_svr:.2f}\")\n",
    "print(f\"R-squared Score: {r2_svr:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3eca6b-63a3-41ea-9c35-23df3d556508",
   "metadata": {},
   "source": [
    "# Support Vector Regressor (SVR)\n",
    "VR (Support Vector Regression) is the regression version of SVM (Support Vector Machine). It tries to find a hyperplane (or curve) that predicts continuous values. The goal is to fit the data within a margin of tolerance (epsilon) — instead of minimizing the error for every point, it ignores small errors and focuses on larger ones. Only data points outside this margin are used to define the model\n",
    "\n",
    "# Why It’s Suitable? \n",
    "-If relationships between features and target are non-linear, SVR with RBF kernel can perform well.\n",
    "-Works well on smaller datasets – this dataset is moderate in size, so it can handle it.\n",
    "-Can model complex boundaries without overfitting (with proper tuning)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25435fc9-a10d-4330-9bf2-21828747e8a4",
   "metadata": {},
   "source": [
    "## Model Evaluation Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcac4f7c-ca63-4747-8ff2-f522943f2683",
   "metadata": {},
   "source": [
    "# How to Choose the Best?\n",
    "\n",
    "1. R² Score: Higher is better → closer to 1.\n",
    "2. MSE & MAE: Lower is better → less error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6de2006d-0756-4504-ad12-3bf196edd07b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance-Comparison:\n",
      "               Model       MSE       MAE  R2 Score\n",
      "0  Linear Regression  0.555892  0.533200  0.575788\n",
      "1      Decision Tree  0.494272  0.453784  0.622811\n",
      "2      Random Forest  0.255498  0.327613  0.805024\n",
      "3  Gradient Boosting  0.293999  0.371650  0.775643\n",
      "4                SVR  0.355198  0.397763  0.728941\n"
     ]
    }
   ],
   "source": [
    "# For better understanding creating a table with all model values\n",
    "\n",
    "# Creating a dictionary with all the results\n",
    "results = {\n",
    "    'Model': ['Linear Regression', 'Decision Tree', 'Random Forest', 'Gradient Boosting', 'SVR'],\n",
    "    'MSE': [mse, mse_dt, mse_rf, mse_gb, mse_svr],\n",
    "    'MAE': [mae, mae_dt, mae_rf, mae_gb, mae_svr],\n",
    "    'R2 Score': [r2, r2_dt, r2_rf, r2_gb, r2_svr]\n",
    "}\n",
    "\n",
    "# Convert to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the table\n",
    "print(\"Model Performance-Comparison:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de47c34a-f6de-48d6-bd60-c45152e832a5",
   "metadata": {},
   "source": [
    "# Best-Performing Algorithm:\n",
    "- Random Forest Regressor performed the best, achieving the lowest MSE and MAE, and the highest R² score (0.81).\n",
    "- It works well for this dataset because it combines multiple decision trees to reduce variance and improve generalization, handling both linear and non-linear patterns effectively.\n",
    "\n",
    "# Worst-Performing Algorithm:\n",
    "-Linear Regression and Support Vector Regressor (SVR) had the lowest R² scores (~0.61–0.62) and higher error rates.\n",
    "-Linear Regression assumes linearity, which may not fully capture complex patterns in housing data.\n",
    "SVR underperformed likely due to sensitivity to hyperparameters and the dataset size, requiring careful tuning to be effective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd786cec-3329-45fb-9cbd-b4983bea25f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
